{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "32a10d89",
      "metadata": {
        "id": "32a10d89"
      },
      "source": [
        "### Name : Avinash Adsare\n",
        "### Roll No : 43501\n",
        "### Sub - NLP\n",
        "### Assignment No - 3\n",
        "Perform text cleaning, perform lemmatization (any method), remove stop words (any method),\n",
        "label encoding. Create representations using TF-IDF. Save outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "581decc1",
      "metadata": {
        "id": "581decc1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c19cf326",
      "metadata": {
        "id": "c19cf326",
        "outputId": "70ae178c-e8f6-4075-871b-e0d8ebccb507"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\Yuvraj\n",
            "[nltk_data]     Pardeshi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\Yuvraj\n",
            "[nltk_data]     Pardeshi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to C:\\Users\\Yuvraj\n",
            "[nltk_data]     Pardeshi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "190d685a",
      "metadata": {
        "id": "190d685a",
        "outputId": "0ad8d59e-6786-446a-952a-7315c7455f47"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is an example of text cleaning and lemmat...</td>\n",
              "      <td>cleaning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We will remove stop words from this text.</td>\n",
              "      <td>removal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Label encoding is important for machine learni...</td>\n",
              "      <td>encoding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TF-IDF is a popular technique for text represe...</td>\n",
              "      <td>representation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text           label\n",
              "0  This is an example of text cleaning and lemmat...        cleaning\n",
              "1          We will remove stop words from this text.         removal\n",
              "2  Label encoding is important for machine learni...        encoding\n",
              "3  TF-IDF is a popular technique for text represe...  representation"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sample data\n",
        "data = {\n",
        "    'text': ['This is an example of text cleaning and lemmatization.',\n",
        "             'We will remove stop words from this text.',\n",
        "             'Label encoding is important for machine learning tasks.',\n",
        "             'TF-IDF is a popular technique for text representation.'],\n",
        "    'label': ['cleaning', 'removal', 'encoding', 'representation']\n",
        "}\n",
        "\n",
        "# Convert data to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5848166",
      "metadata": {
        "id": "e5848166"
      },
      "outputs": [],
      "source": [
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    return text\n",
        "\n",
        "# Lemmatization function\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    lemmatized_text = ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n",
        "    return lemmatized_text\n",
        "\n",
        "# Remove stop words function\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    filtered_text = ' '.join([word for word in tokens if word not in stop_words])\n",
        "    return filtered_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7467791",
      "metadata": {
        "id": "d7467791",
        "outputId": "d12f5663-b4ec-439c-b937-60908c52b80b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    this is an example of text cleaning and lemmat...\n",
              "1             we will remove stop words from this text\n",
              "2    label encoding is important for machine learni...\n",
              "3    tfidf is a popular technique for text represen...\n",
              "Name: cleaned_text, dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['cleaned_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acfa037e",
      "metadata": {
        "id": "acfa037e",
        "outputId": "cc913a4f-8625-45be-b14f-c5d5affd5f1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    this is an example of text cleaning and lemmat...\n",
              "1              we will remove stop word from this text\n",
              "2    label encoding is important for machine learni...\n",
              "3    tfidf is a popular technique for text represen...\n",
              "Name: lemmatized_text, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['lemmatized_text'] = df['cleaned_text'].apply(lemmatize_text)\n",
        "df['lemmatized_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4117590",
      "metadata": {
        "id": "c4117590",
        "outputId": "1ee13564-b5a9-4c79-cc7c-f346aa8763d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0               example text cleaning lemmatization\n",
              "1                             remove stop word text\n",
              "2    label encoding important machine learning task\n",
              "3       tfidf popular technique text representation\n",
              "Name: processed_text, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['processed_text'] = df['lemmatized_text'].apply(remove_stopwords)\n",
        "df['processed_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "927c40bb",
      "metadata": {
        "id": "927c40bb",
        "outputId": "494b2cc9-81a7-4899-9fa3-abab4a61b5f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed Data:\n",
            "                                                text           label  \\\n",
            "0  This is an example of text cleaning and lemmat...        cleaning   \n",
            "1          We will remove stop words from this text.         removal   \n",
            "2  Label encoding is important for machine learni...        encoding   \n",
            "3  TF-IDF is a popular technique for text represe...  representation   \n",
            "\n",
            "                                        cleaned_text  \\\n",
            "0  this is an example of text cleaning and lemmat...   \n",
            "1           we will remove stop words from this text   \n",
            "2  label encoding is important for machine learni...   \n",
            "3  tfidf is a popular technique for text represen...   \n",
            "\n",
            "                                     lemmatized_text  \\\n",
            "0  this is an example of text cleaning and lemmat...   \n",
            "1            we will remove stop word from this text   \n",
            "2  label encoding is important for machine learni...   \n",
            "3  tfidf is a popular technique for text represen...   \n",
            "\n",
            "                                   processed_text  encoded_label  \n",
            "0             example text cleaning lemmatization              0  \n",
            "1                           remove stop word text              2  \n",
            "2  label encoding important machine learning task              1  \n",
            "3     tfidf popular technique text representation              3  \n"
          ]
        }
      ],
      "source": [
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['encoded_label'] = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "# Print processed data\n",
        "print(\"Processed Data:\")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5833ebd",
      "metadata": {
        "id": "f5833ebd",
        "outputId": "c65bd09c-30e3-4097-87b5-23df78f2b43d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sentences with TF-IDF Representation:\n",
            "Sentence: example text cleaning lemmatization\n",
            "TF-IDF Representation: [[0.5417361  0.         0.5417361  0.         0.         0.\n",
            "  0.5417361  0.         0.         0.         0.         0.\n",
            "  0.         0.         0.34578314 0.         0.        ]]\n",
            "\n",
            "Sentence: remove stop word text\n",
            "TF-IDF Representation: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.5417361  0.         0.5417361\n",
            "  0.         0.         0.34578314 0.         0.5417361 ]]\n",
            "\n",
            "Sentence: label encoding important machine learning task\n",
            "TF-IDF Representation: [[0.         0.40824829 0.         0.40824829 0.40824829 0.40824829\n",
            "  0.         0.40824829 0.         0.         0.         0.\n",
            "  0.40824829 0.         0.         0.         0.        ]]\n",
            "\n",
            "Sentence: tfidf popular technique text representation\n",
            "TF-IDF Representation: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.47633035 0.         0.47633035 0.\n",
            "  0.         0.47633035 0.30403549 0.47633035 0.        ]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF representation\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_representation = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
        "\n",
        "# Print TF-IDF representation in detail\n",
        "print(\"\\nSentences with TF-IDF Representation:\")\n",
        "for i, sentence in enumerate(df['processed_text']):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"TF-IDF Representation:\", tfidf_representation[i].toarray())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cf92d89",
      "metadata": {
        "id": "0cf92d89"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}